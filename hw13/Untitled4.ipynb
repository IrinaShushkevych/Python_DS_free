{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YJM1AH4JxqSW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Частина 1"
      ],
      "metadata": {
        "id": "jQSe8OLmx5_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "tmzm4Vqmx4nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ad0e0e-8821-465d-945f-1aed1fc532db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)"
      ],
      "metadata": {
        "id": "2hk16wXGx5Yn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "9-lGp46jyBB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9029ca70-4621-4dc2-9f1d-295a1720b992"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Lfo4U1iHyVHA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "epochs = 30\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "XF4xx7NUyZ9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def1c805-4cc9-4246-8901-97a3b5cec28f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 154ms/step - accuracy: 0.6644 - loss: 0.9186 - val_accuracy: 0.8330 - val_loss: 0.4640\n",
            "Epoch 2/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 151ms/step - accuracy: 0.8369 - loss: 0.4483 - val_accuracy: 0.8687 - val_loss: 0.3638\n",
            "Epoch 3/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 151ms/step - accuracy: 0.8702 - loss: 0.3631 - val_accuracy: 0.8848 - val_loss: 0.3247\n",
            "Epoch 4/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 150ms/step - accuracy: 0.8773 - loss: 0.3333 - val_accuracy: 0.8886 - val_loss: 0.3049\n",
            "Epoch 5/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 144ms/step - accuracy: 0.8862 - loss: 0.3128 - val_accuracy: 0.8946 - val_loss: 0.2888\n",
            "Epoch 6/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 149ms/step - accuracy: 0.8928 - loss: 0.2908 - val_accuracy: 0.8946 - val_loss: 0.2859\n",
            "Epoch 7/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 143ms/step - accuracy: 0.8995 - loss: 0.2708 - val_accuracy: 0.9004 - val_loss: 0.2684\n",
            "Epoch 8/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 142ms/step - accuracy: 0.9047 - loss: 0.2610 - val_accuracy: 0.9058 - val_loss: 0.2563\n",
            "Epoch 9/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 155ms/step - accuracy: 0.9071 - loss: 0.2526 - val_accuracy: 0.9002 - val_loss: 0.2636\n",
            "Epoch 10/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 152ms/step - accuracy: 0.9119 - loss: 0.2359 - val_accuracy: 0.9124 - val_loss: 0.2379\n",
            "Epoch 11/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 150ms/step - accuracy: 0.9134 - loss: 0.2339 - val_accuracy: 0.9105 - val_loss: 0.2449\n",
            "Epoch 12/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 150ms/step - accuracy: 0.9200 - loss: 0.2191 - val_accuracy: 0.9106 - val_loss: 0.2438\n",
            "Epoch 13/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 150ms/step - accuracy: 0.9206 - loss: 0.2119 - val_accuracy: 0.9184 - val_loss: 0.2237\n",
            "Epoch 14/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 149ms/step - accuracy: 0.9234 - loss: 0.2014 - val_accuracy: 0.9166 - val_loss: 0.2238\n",
            "Epoch 15/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 151ms/step - accuracy: 0.9263 - loss: 0.1951 - val_accuracy: 0.9144 - val_loss: 0.2314\n",
            "Epoch 16/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 146ms/step - accuracy: 0.9281 - loss: 0.1901 - val_accuracy: 0.9139 - val_loss: 0.2364\n",
            "Epoch 17/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.9316 - loss: 0.1835 - val_accuracy: 0.9119 - val_loss: 0.2383\n",
            "Epoch 18/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 152ms/step - accuracy: 0.9323 - loss: 0.1790 - val_accuracy: 0.9177 - val_loss: 0.2230\n",
            "Epoch 19/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 153ms/step - accuracy: 0.9374 - loss: 0.1695 - val_accuracy: 0.9204 - val_loss: 0.2230\n",
            "Epoch 20/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 148ms/step - accuracy: 0.9384 - loss: 0.1675 - val_accuracy: 0.9216 - val_loss: 0.2152\n",
            "Epoch 21/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 151ms/step - accuracy: 0.9405 - loss: 0.1582 - val_accuracy: 0.9254 - val_loss: 0.2153\n",
            "Epoch 22/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 153ms/step - accuracy: 0.9397 - loss: 0.1577 - val_accuracy: 0.9229 - val_loss: 0.2200\n",
            "Epoch 23/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - accuracy: 0.9434 - loss: 0.1530 - val_accuracy: 0.9228 - val_loss: 0.2218\n",
            "Epoch 24/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 151ms/step - accuracy: 0.9421 - loss: 0.1514 - val_accuracy: 0.9251 - val_loss: 0.2152\n",
            "Epoch 25/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 152ms/step - accuracy: 0.9442 - loss: 0.1458 - val_accuracy: 0.9242 - val_loss: 0.2210\n",
            "Epoch 26/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - accuracy: 0.9486 - loss: 0.1390 - val_accuracy: 0.9205 - val_loss: 0.2247\n",
            "Epoch 27/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 152ms/step - accuracy: 0.9501 - loss: 0.1303 - val_accuracy: 0.9213 - val_loss: 0.2252\n",
            "Epoch 28/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 149ms/step - accuracy: 0.9504 - loss: 0.1332 - val_accuracy: 0.9281 - val_loss: 0.2195\n",
            "Epoch 29/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 152ms/step - accuracy: 0.9495 - loss: 0.1284 - val_accuracy: 0.9259 - val_loss: 0.2254\n",
            "Epoch 30/30\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 149ms/step - accuracy: 0.9526 - loss: 0.1223 - val_accuracy: 0.9251 - val_loss: 0.2259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Точність на тестових даних: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "sEBfgeE-ydm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3aefa1-64a1-432f-bc7f-bda7aa754d85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9262 - loss: 0.2236\n",
            "Точність на тестових даних: 92.51%\n"
          ]
        }
      ]
    }
  ]
}